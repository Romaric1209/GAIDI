{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOxn/9XqRs4cEO8/UwIwvst"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import DataLoader, WeightedRandomSampler\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import StratifiedKFold\n","import torch.optim as optim\n","from torchvision import transforms, datasets\n","from PIL import Image\n","from tqdm import tqdm"],"metadata":{"id":"IQNNoBIKIlzS","executionInfo":{"status":"ok","timestamp":1752478989913,"user_tz":-480,"elapsed":9943,"user":{"displayName":"Romaric Berger","userId":"00619562086203818771"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hnxa9Dip2Tj6","executionInfo":{"status":"ok","timestamp":1752479015796,"user_tz":-480,"elapsed":25879,"user":{"displayName":"Romaric Berger","userId":"00619562086203818771"}},"outputId":"f19712ba-d4a9-41f3-a1fc-519c66cea936"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Torch Model"],"metadata":{"id":"IpaXWcEePxN2"}},{"cell_type":"markdown","source":["## Training modules"],"metadata":{"id":"zjFa88q_GoEP"}},{"cell_type":"code","source":["## After splitting, we need a way to load images + labels from our lists of X and y ‚Äî that‚Äôs where FrameDataset comes in.\n","from torch.utils.data import Dataset\n","from PIL import Image\n","\n","class FrameDataset(Dataset):\n","    def __init__(self, image_paths, labels, transform = None):\n","        self.image_paths = image_paths\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self,idx):\n","        image = Image.open(self.image_paths[idx]).convert('RGB')\n","        label = self.labels[idx]\n","\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label"],"metadata":{"id":"FblLiei0h6CN","executionInfo":{"status":"ok","timestamp":1752479015804,"user_tz":-480,"elapsed":4,"user":{"displayName":"Romaric Berger","userId":"00619562086203818771"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Model\n","class DeepF_CNN(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            # Block 1\n","            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),  # padding='same' ‚Üí padding=1 when kernel=3\n","            nn.ReLU(),\n","            nn.BatchNorm2d(num_features=32),  # because output channels = 32\n","            nn.MaxPool2d(kernel_size=2),\n","            nn.Dropout(p=0.2),\n","\n","            # Block 2\n","            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(num_features=64),\n","            nn.MaxPool2d(kernel_size=2),\n","            nn.Dropout(p=0.3),\n","\n","            # Block 3\n","            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","            nn.ReLU(),\n","            nn.BatchNorm2d(128),\n","            nn.AdaptiveAvgPool2d((1, 1)),  # ‚Üí output shape [batch, 128, 1, 1]\n","            nn.Flatten(),                  # ‚Üí [batch, 128]\n","\n","            nn.Linear(128, 1),\n","            nn.Sigmoid()\n","            )\n","    def forward(self, x):\n","        return self.net(x)"],"metadata":{"id":"zsiszNY9VOTh","executionInfo":{"status":"ok","timestamp":1752479015810,"user_tz":-480,"elapsed":2,"user":{"displayName":"Romaric Berger","userId":"00619562086203818771"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#Create ES function\n","class EarlyStopping:\n","    def __init__(self, patience=5):\n","        self.patience = patience\n","        self.counter = 0\n","        self.best_loss = float('inf')\n","        self.best_model = None\n","        self.early_stop = False\n","\n","    def __call__(self, val_loss, model):\n","        if val_loss < self.best_loss:\n","            self.best_loss = val_loss\n","            self.best_model = model.state_dict() # saves best weight\n","            self.counter = 0\n","        else:\n","            self.counter += 1\n","            if self.counter >= self.patience:\n","                self.early_stop = True"],"metadata":{"id":"OYasrYzb4AzX","executionInfo":{"status":"ok","timestamp":1752479016281,"user_tz":-480,"elapsed":50,"user":{"displayName":"Romaric Berger","userId":"00619562086203818771"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Define a training session ( will be x5)\n","def train_one_fold(X, y, fold_idx, train_idx, val_idx, transform, device):\n","    print(f\"Training Fold {fold_idx + 1}...\")\n","\n","    # Datasets\n","    train_dataset = FrameDataset(X[train_idx], y[train_idx], transform)\n","    val_dataset   = FrameDataset(X[val_idx], y[val_idx], transform)\n","\n","    # Weighted sampling\n","    class_counts = np.bincount(y[train_idx])\n","    weights = 1. / class_counts\n","    sample_weights = weights[y[train_idx]]\n","    sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n","\n","    # Dataloaders\n","    train_loader = DataLoader(train_dataset, batch_size=32, sampler=sampler)\n","    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n","\n","    # Model, loss, optimizer\n","    model = DeepF_CNN().to(device)\n","    criterion = nn.BCEWithLogitsLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3)\n","    early_stopper = EarlyStopping(patience=5)\n","\n","    for epoch in range(30):\n","        model.train()\n","        running_loss, correct, total = 0.0, 0, 0\n","        for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n","            images, labels = images.to(device), labels.float().unsqueeze(1).to(device)\n","            optimizer.zero_grad()\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item() * labels.size(0)\n","            preds = torch.sigmoid(outputs) >= 0.5\n","            correct += (preds == labels).sum().item()\n","            total += labels.size(0)\n","\n","        train_acc = correct / total\n","        train_loss = running_loss / total\n","\n","        # Validation\n","        model.eval()\n","        val_loss, val_correct, val_total = 0.0, 0, 0\n","        with torch.no_grad():\n","            for images, labels in val_loader:\n","                images, labels = images.to(device), labels.float().unsqueeze(1).to(device)\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","                val_loss += loss.item() * labels.size(0)\n","                preds = torch.sigmoid(outputs) >= 0.5\n","                val_correct += (preds == labels).sum().item()\n","                val_total += labels.size(0)\n","\n","        val_loss /= val_total\n","        val_acc = val_correct / val_total\n","\n","        print(f\"Epoch {epoch+1} | Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n","        scheduler.step(val_loss)\n","        early_stopper(val_loss, model)\n","\n","        if early_stopper.early_stop:\n","            print(\"Early stopping triggered.\")\n","            break\n","\n","    # Return best model for this fold\n","    model.load_state_dict(early_stopper.best_model)\n","    return model\n"],"metadata":{"id":"1Npc_A5H5Wqv","executionInfo":{"status":"ok","timestamp":1752481295658,"user_tz":-480,"elapsed":26,"user":{"displayName":"Romaric Berger","userId":"00619562086203818771"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["# Prepare data"],"metadata":{"id":"2oDNge5VAI4R"}},{"cell_type":"code","source":["import shutil\n","\n","# # Only copy once\n","# !rm -rf /content/local_data  # Clean up if re-running\n","shutil.copytree('/content/drive/MyDrive/Colab_Notebooks/GAIDI/Deepfake/data', '/content/local_data')\n","\n","# data = datasets.ImageFolder(root='/content/local_data', transform=transform)  <== below\n"],"metadata":{"id":"Y3da47v4cuXU","executionInfo":{"status":"ok","timestamp":1752479754644,"user_tz":-480,"elapsed":727003,"user":{"displayName":"Romaric Berger","userId":"00619562086203818771"}},"colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"4e275f0c-9008-4119-c6a8-72eb53971c50"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/local_data'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["from collections import Counter\n","\n","transform = transforms.Compose([\n","    transforms.Resize((32,32)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)\n","])\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(\"Using device:\", device)\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42) # 5 fold\n","\n","# data = datasets.ImageFolder(root='/content/drive/MyDrive/Colab_Notebooks/GAIDI/Deepfake/data', transform=transform)\n","data = datasets.ImageFolder(root='/content/local_data', transform=transform) #  <== after copying the dataset to colab local disk with shutil\n","class_counts = Counter(data.targets)\n","\n","print(f'data has two classes: {data.classes}, there are {len(data)} images(frames) in data, {class_counts[1]} real video frames, {class_counts[0]} fake video frames')\n","\n","if ((class_counts[0] * 100) / class_counts[1]) < 45 or ((class_counts[0] * 100) / class_counts[1]) > 55:\n","    print('classes weights are imbalanced, WeightedRandomSampler is required')\n","else:\n","    print('classes weights are balanced, no WeightedRandomSampler required.')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NmRuPG4W5ZNo","executionInfo":{"status":"ok","timestamp":1752481169105,"user_tz":-480,"elapsed":112,"user":{"displayName":"Romaric Berger","userId":"00619562086203818771"}},"outputId":"340cace9-db73-4b9d-aa28-ccaf59a02ec1"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n","data has two classes: ['fake', 'real'], there are 19061 images(frames) in data, 8332 real video frames, 10729 fake video frames\n","classes weights are imbalanced, WeightedRandomSampler is required\n"]}]},{"cell_type":"code","source":["X = np.array([s[0] for s in data.samples])\n","y = np.array([s[1] for s in data.samples])"],"metadata":{"id":"DdXUaiZA_uiv","executionInfo":{"status":"ok","timestamp":1752479754799,"user_tz":-480,"elapsed":33,"user":{"displayName":"Romaric Berger","userId":"00619562086203818771"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y)"],"metadata":{"id":"x9lD5oIB_5Hz","executionInfo":{"status":"ok","timestamp":1752479754832,"user_tz":-480,"elapsed":30,"user":{"displayName":"Romaric Berger","userId":"00619562086203818771"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["print(f'{X_train.shape}\\n{ X_val.shape}\\n{y_train.shape}\\n{y_val.shape}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"53MirsE9__cq","executionInfo":{"status":"ok","timestamp":1752479754866,"user_tz":-480,"elapsed":29,"user":{"displayName":"Romaric Berger","userId":"00619562086203818771"}},"outputId":"0ef00c5f-5398-4d6a-9562-c4485eb31c0f"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["(15248,)\n","(3813,)\n","(15248,)\n","(3813,)\n"]}]},{"cell_type":"markdown","source":["# Train"],"metadata":{"id":"cHxsXBmGADYW"}},{"cell_type":"code","source":["!nvidia-smi\n"],"metadata":{"id":"cMmOVeyS9LU0","executionInfo":{"status":"aborted","timestamp":1752481544362,"user_tz":-480,"elapsed":87785,"user":{"displayName":"Romaric Berger","userId":"00619562086203818771"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n","    model = train_one_fold(X, y, fold_idx, train_idx, val_idx, transform, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"id":"ECSWW_jT_kD-","executionInfo":{"status":"error","timestamp":1752481544354,"user_tz":-480,"elapsed":220254,"user":{"displayName":"Romaric Berger","userId":"00619562086203818771"}},"outputId":"1103147c-535b-4b6a-9a10-bb3a9f200f9e"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Training Fold 1...\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 477/477 [02:37<00:00,  3.03it/s]\n"]},{"output_type":"stream","name":"stdout","text":["üìä Epoch 1 | Train Loss: 0.6264, Val Loss: 0.5895, Val Acc: 0.4372\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2:  14%|‚ñà‚ñç        | 68/477 [00:23<02:22,  2.88it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-22-3040854097.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfold_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_idx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_one_fold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfold_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipython-input-21-644034095.py\u001b[0m in \u001b[0;36mtrain_one_fold\u001b[0;34m(X, y, fold_idx, train_idx, val_idx, transform, device)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mrunning_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipython-input-3-2095838687.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0mdeprecate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0mhas_transparency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"transparency\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["labels = labels.float().unsqueeze(1)\n","outputs = model(images)\n","preds = torch.sigmoid(outputs) >= 0.5  # ‚Üê Make sure this matches label format\n","print(labels, outputs, preds,labels.shape, preds.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":201},"id":"PbybL6v8RT2e","executionInfo":{"status":"error","timestamp":1752403658963,"user_tz":-480,"elapsed":99,"user":{"displayName":"Romaric Berger","userId":"00619562086203818771"}},"outputId":"bda46dd4-8087-4e0b-829b-b9ef01804d61"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'labels' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-84-2997845460.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m  \u001b[0;31m# ‚Üê Make sure this matches label format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"]}]},{"cell_type":"code","source":["print(\"Full data:\", np.bincount(y))        # Should be [10729, 8332]\n","print(\"Train:\", np.bincount(y[train_idx])) # Should be ~85% of that\n","print(\"Val:\", np.bincount(y[val_idx]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J-11bBh2RrG8","executionInfo":{"status":"ok","timestamp":1752403942443,"user_tz":-480,"elapsed":100,"user":{"displayName":"Romaric Berger","userId":"00619562086203818771"}},"outputId":"0973e27a-dd91-47da-a043-c0e746d1639c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Full data: [10729  8332]\n","Train: [8583 6665]\n","Val: [2146 1667]\n"]}]},{"cell_type":"markdown","source":["## save model"],"metadata":{"id":"0UXaLeQA9RTg"}},{"cell_type":"code","source":["torch.save({\n","    'model_state_dict': model.state_dict(),\n","    'optimizer_state_dict': optimizer.state_dict(),\n","    'scheduler_state_dict': scheduler.state_dict(),\n","}, 'model_fold1.pth')\n"],"metadata":{"id":"LyMmELHD9TMT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Load model"],"metadata":{"id":"YfnnASVv9VpC"}},{"cell_type":"code","source":["checkpoint = torch.load('model_fold1.pth', map_location=device)\n","model.load_state_dict(checkpoint['model_state_dict'])\n","optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","scheduler.load_state_dict(checkpoint['scheduler_state_dict'])"],"metadata":{"id":"Q5kZ8ZRu9ZAY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for fold_idx, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n","\n","    # Load or initialize model\n","    model = DeepF_CNN().to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, ...)\n","\n","    # Load from checkpoint if continuing\n","    checkpoint_path = f\"model_fold{fold_idx+1}.pth\"\n","    if os.path.exists(checkpoint_path):\n","        checkpoint = torch.load(checkpoint_path, map_location=device)\n","        model.load_state_dict(checkpoint['model_state_dict'])\n","        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n","        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n","        print(f\"Resumed model for fold {fold_idx+1}\")\n","\n","    # Train model as usual\n","    trained_model = train_one_fold(...)\n","\n","    # Save everything after training\n","    torch.save({\n","        'model_state_dict': trained_model.state_dict(),\n","        'optimizer_state_dict': optimizer.state_dict(),\n","        'scheduler_state_dict': scheduler.state_dict(),\n","    }, checkpoint_path)"],"metadata":{"id":"4DZlKquq9hFb"},"execution_count":null,"outputs":[]}]}